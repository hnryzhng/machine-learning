{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2f1301",
   "metadata": {},
   "source": [
    "course: https://learn.deeplearning.ai/courses/pytorch-fundamentals/\n",
    "\n",
    "lesson: https://learn.deeplearning.ai/specializations/pytorch-for-deep-learning-professional-certificate/lesson/466v5tii/building-a-simple-neural-network\n",
    "\n",
    "based off of lab: \n",
    "https://learn.deeplearning.ai/specializations/pytorch-for-deep-learning-professional-certificate/lesson/x77awl3j/modeling-non-linear-patterns-with-activation-functions \n",
    "\n",
    "\n",
    "LESSON CONCEPTS\n",
    "Nonlinear Modeling with Activation Functions\n",
    "+ \n",
    "Normalization\n",
    "\n",
    "\n",
    "Expands on ```pytorch-fundamentals-1-basic-ml-pipeline.ipynb```\n",
    "\n",
    "Activation functions\n",
    "Great explanations and illustrations: https://learn.deeplearning.ai/specializations/pytorch-for-deep-learning-professional-certificate/lesson/hllrjryf/activation-functions\n",
    "\n",
    "- Refer to screenshots for ReLU\n",
    "\n",
    "- Standard activation functions: ReLU, Sigmoid, TanH\n",
    "\n",
    "\n",
    "\n",
    "Lesson verbiage:\n",
    "In the last lab, your simple linear model performed well on bike-only data, but it struggled when cars were added. The reason was simple: your model could only learn straight lines, but the new data followed a curve. As you saw in the lectures, simply adding more linear neurons is not the solution. The model's output would still be a straight line.\n",
    "\n",
    "This is where non-linear activation functions come in. They are the key to unlocking your model's ability to learn the complex, curved patterns found in real-world data. In this lab, you'll use the most popular and powerful activation function, ReLU (Rectified Linear Unit), to build a more sophisticated model. By adding a ReLU activation, your model can create multiple \"bends\" that can approximate the complex delivery time curve.\n",
    "\n",
    "In this lab, you will:\n",
    "\n",
    "Prepare the combined bike and car delivery data, this time applying a technique called normalization to help your model train more effectively.\n",
    "Build a non-linear neural network using the ReLU activation function.\n",
    "Train your new model to learn the complex, curved relationship in the data.\n",
    "Predict delivery times using your new model and see if it can finally succeed where the linear one failed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn   # neural network\n",
    "import torch.optim as optim # optimization algorithms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df698e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Ingestion \n",
    "\n",
    "# more complex data than first notebook for both bike and car deliveries\n",
    "\n",
    "distances_data = [\n",
    "    [1.0], [1.5], [2.0], [2.5], [3.0], [3.5], [4.0], [4.5], [5.0], [5.5],\n",
    "    [6.0], [6.5], [7.0], [7.5], [8.0], [8.5], [9.0], [9.5], [10.0], [10.5],\n",
    "    [11.0], [11.5], [12.0], [12.5], [13.0], [13.5], [14.0], [14.5], [15.0], [15.5],\n",
    "    [16.0], [16.5], [17.0], [17.5], [18.0], [18.5], [19.0], [19.5], [20.0]\n",
    "]\n",
    "\n",
    "delivery_times_data = [\n",
    "    [6.96], [9.67], [12.11], [14.56], [16.77], [21.7], [26.52], [32.47], [37.15], [42.35],\n",
    "    [46.1], [52.98], [57.76], [61.29], [66.15], [67.63], [69.45], [71.57], [72.8], [73.88],\n",
    "    [76.34], [76.38], [78.34], [80.07], [81.86], [84.45], [83.98], [86.55], [88.33], [86.83],\n",
    "    [89.24], [88.11], [88.16], [91.77], [92.27], [92.13], [90.73], [90.39], [92.98]\n",
    "]\n",
    "\n",
    "# input tensor\n",
    "distances_tensor = torch.tensor(\n",
    "    distances_data,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "# output tensor\n",
    "delivery_times_tensor = torch.tensor(\n",
    "    delivery_times_data,\n",
    "    dtype=torch.float32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Preparation\n",
    "\n",
    "# Normalization\n",
    "\"\"\"\n",
    "Lesson notes:\n",
    "\n",
    "This is astandard technique that makes the training process more stable and effective by adjusting the scale of the data. This adjustment helps prevent large distance values from dominating the learning process and keeps gradients stable during training.\n",
    "\n",
    "You will calculate the mean and standard deviation for the distances and times tensors.\n",
    "You will then apply standardization to each tensor using its respective mean and standard deviation, which creates new normalized tensors named distances_norm and times_norm.\n",
    "This specific technique is called standardization (or z-score normalization), which converts the original data from 1.0 to 20.0 miles and approximately 7 to 93 minutes into a new, normalized scale.\n",
    "\"\"\"\n",
    "\n",
    "distances_mean = distances_tensor.mean()\n",
    "distances_std = distances_tensor.std()\n",
    "\n",
    "delivery_times_mean = delivery_times_tensor.mean()\n",
    "delivery_times_std = delivery_times_tensor.std()\n",
    "\n",
    "# normalized tensors\n",
    "distances_tensor_normalized = (distances_tensor - distances_mean) / distances_std\n",
    "delivery_times_tensor_normalized = (delivery_times_tensor - delivery_times_mean) / delivery_times_std\n",
    "\n",
    "# print(f\"Distances normalized: {distances_tensor_normalized[:5]}\")\n",
    "# print(f\"Delivery times normalized: {delivery_times_tensor_normalized[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model\n",
    "\n",
    "# define model\n",
    "\"\"\"\n",
    "Lesson notes:\n",
    "nn.Linear(1, 3): This is your first hidden layer. It consists of three neurons, each receiving one input feature (the normalized distance). This layer transforms the single input value into three separate values.\n",
    "nn.ReLU() applies the ReLU activation function to the output of each of the three neurons from the hidden layer. This is the crucial non-linear step that allows your model to create \"bends\" and learn curves instead of just straight lines.\n",
    "nn.Linear(3, 1): This is your output layer. It takes the three activated values from the previous step as its input and combines them to produce a single final output, which is your predicted (normalized) delivery time.\n",
    "\"\"\"\n",
    "\n",
    "torch.manual_seed(27)   # ensures results are reproducible\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=1, out_features=3),  # hidden layer\n",
    "    nn.ReLU(),                                # activation function\n",
    "    nn.Linear(in_features=3, out_features=1) # output layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac24e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_function = nn.MSELoss()   # mean squared error loss\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.01   # learning rate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a506c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: plot_training_progress\n",
    "\n",
    "def plot_training_progress(\n",
    "    epoch,\n",
    "    loss,\n",
    "    model,\n",
    "    input_data_normalized,\n",
    "    target_data_normalized\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Course notes:\n",
    "    Plots the training progress of a model on normalized data,\n",
    "    showing the current fit at each epoch.\n",
    "\n",
    "    Args:\n",
    "        epoch: The current training epoch number.\n",
    "        loss: The loss value at the current epoch.\n",
    "        model: The model being trained.\n",
    "        input_data_normalized (distances_norm)\n",
    "        target_data_normalized (times_norm)\n",
    "    \"\"\"\n",
    "\n",
    "    predicted_target_data_normalized = model(input_data_normalized)\n",
    "    \n",
    "    # convert tensors to NumPy arrays for plotting\n",
    "    x_plot = input_data_normalized.numpy()\n",
    "    y_plot = target_data_normalized.numpy()\n",
    "\n",
    "    # detach predictions from the computation graph and convert to NumPy\n",
    "    y_pred_plot = predicted_target_data_normalized.detach().numpy()\n",
    "\n",
    "    # sort the data based on distance to ensure a smooth line plot\n",
    "    sorted_indices = x_plot.argsort(axis=0).flatten()\n",
    "\n",
    "    # create new figure for the plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # plot the original normalized data points\n",
    "    plt.plot(x_plot, y_plot, color='orange', marker='o', linestyle='none', label='Actual Normalized Data')\n",
    "\n",
    "    # plot the model's predictions as a line\n",
    "    plt.plot(x_plot[sorted_indices], y_pred_plot[sorted_indices], color='green', label='Model Predictions')\n",
    "\n",
    "    # set chart elements\n",
    "    plt.title(f'Epoch: {epoch + 1} | Normalized Training Progress')\n",
    "    plt.xlabel('Normalized Distance')\n",
    "    plt.ylabel('Normalized Time')\n",
    "\n",
    "    # show legend\n",
    "    plt.legend()\n",
    "\n",
    "    # show grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training\n",
    "\n",
    "\"\"\"\n",
    "Lesson notes:\n",
    "You will run the training loop for 3000 epochs (more than Lab 1 because the non-linear pattern is more complex and requires more training). This will repeatedly feed the normalized data to your model, measure the error, and adjust the model's parameters to improve its predictions.\n",
    "The second half of the code includes a live plot, allowing you to watch in real time as your model's prediction line adapts to fit the curved data. The live plot helps you see how your model gradually learns to fit the curve, starting with a poor fit and improving over time.\n",
    "\"\"\"\n",
    "\n",
    "# training loop\n",
    "NUM_EPOCHS = 3000\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    # reset optimizer's gradients for each loop so adjustments don't accumulate\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    predicted_outputs = model(distances_tensor_normalized)\n",
    "\n",
    "    # calculate loss\n",
    "    loss = loss_function(\n",
    "        predicted_outputs,\n",
    "        delivery_times_tensor_normalized    # actual outputs\n",
    "    )\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "    # update model parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # print and live plot training progress\n",
    "    # plot every 50 epochs\n",
    "    # TODO...\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # TODO...\n",
    "        # plot_training_progress helper function\n",
    "        plot_training_progress(\n",
    "            epoch,\n",
    "            loss,\n",
    "            model,\n",
    "            distances_tensor_normalized,\n",
    "            delivery_times_tensor_normalized\n",
    "        )\n",
    "\n",
    "print(\"\\nTraining complete.\\n\")\n",
    "print(f\"Final loss: {loss.item()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fefd2e9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
